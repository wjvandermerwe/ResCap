{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T05:51:15.047990Z",
     "start_time": "2024-08-09T05:51:14.692940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.config import load_datasets, get_train_dataset_indexes\n",
    "\n",
    "dataset_indexes = get_train_dataset_indexes(\"../outputs/datasets\")\n",
    "datasets = load_datasets(folder=\"../outputs/datasets\", names=dataset_indexes)\n"
   ],
   "id": "a89efe4305ed9eac",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T05:51:26.930877Z",
     "start_time": "2024-08-09T05:51:22.715650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import SurvivalAnalysisDataLoader\n",
    "\n",
    "\n",
    "# https://github.com/vanderschaarlab/synthcity/issues/249\n",
    "def run_surv_gan(data_loader, device):\n",
    "    model = Plugins().get(\"survival_gan\", device=device)\n",
    "    model.fit(data_loader)\n",
    "    return model\n",
    "    \n",
    "def run_surv_vae(data_loader, device):\n",
    "    model = Plugins().get(\"survae\", device=device)\n",
    "    model.fit(data_loader)\n",
    "    return model"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\anaconda3\\envs\\reseach_project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T05:51:28.394800Z",
     "start_time": "2024-08-09T05:51:28.389770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from synthcity.metrics.eval_sanity import CloseValuesProbability, DataMismatchScore, CommonRowsProportion, NearestSyntheticNeighborDistance, DistantValuesProbability\n",
    "\n",
    "def evaluate_model(data_loader, generated_data):\n",
    "    # Initialize metrics\n",
    "    close = CloseValuesProbability()\n",
    "    data_mismatch = DataMismatchScore()\n",
    "    proportion = CommonRowsProportion()\n",
    "    nn_distance = NearestSyntheticNeighborDistance()\n",
    "    distant = DistantValuesProbability()\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    close_val = close.evaluate(data_loader, generated_data)\n",
    "    mis = data_mismatch.evaluate(data_loader, generated_data)\n",
    "    prop = proportion.evaluate(data_loader, generated_data)\n",
    "    nn_dist = nn_distance.evaluate(data_loader, generated_data)\n",
    "    dist = distant.evaluate(data_loader, generated_data)\n",
    "    \n",
    "    # Determine if metrics are within expected values\n",
    "    correct = True\n",
    "    \n",
    "    # Define correctness based on descriptions\n",
    "    if not (0 <= close_val <= 1):\n",
    "        correct = False\n",
    "    if not (0 <= mis <= 1):\n",
    "        correct = False\n",
    "    if not (0 <= prop <= 1):\n",
    "        correct = False\n",
    "    if nn_dist < 0:\n",
    "        correct = False\n",
    "    if not (0 <= dist <= 1):\n",
    "        correct = False\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'close_values': {\n",
    "            \"value\": close_val,\n",
    "            \"description\": \"0 means there is no chance to have synthetic rows similar to the real. 1 means that all the synthetic rows are similar to some real rows.\"\n",
    "        },\n",
    "        'data_mismatch': {\n",
    "            \"value\": mis,\n",
    "            \"description\": \"0: no datatype mismatch. 1: complete data type mismatch between the datasets.\"\n",
    "        },\n",
    "        'proportion': {\n",
    "            \"value\": prop,\n",
    "            \"description\": \"0: there are no common rows between the real and synthetic datasets. 1: all the rows in the real dataset are leaked in the synthetic dataset.\",\n",
    "        },\n",
    "        'nn_distance': {\n",
    "            \"value\": nn_dist,\n",
    "            \"description\": \"Computes the distance from the real data to the closest neighbor in the synthetic data\"\n",
    "        },\n",
    "        'distant_values': {\n",
    "            \"value\": dist,\n",
    "            \"description\": \"0 means there is no chance to have rows in the synthetic far away from the real data. 1 means all the synthetic datapoints are far away from the real data.\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results, correct\n"
   ],
   "id": "5e07eb06a09ca576",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T06:46:33.061942Z",
     "start_time": "2024-08-09T06:46:33.055242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.preprocess import impute_missing_values\n",
    "from synthcity.utils.serialization import save_to_file\n",
    "from utils.config import save_dataset, save_checkpoint, load_checkpoint\n",
    "import torch\n",
    "start_index = load_checkpoint()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "for index, dataset_index in enumerate(dataset_indexes):\n",
    "    if index <= start_index:\n",
    "        continue\n",
    "    print(f\"training model on {dataset_index}\")\n",
    "    ds_train = datasets[dataset_index]\n",
    "    ds_train = impute_missing_values(ds_train)\n",
    "    # print(ds_train.head())\n",
    "    data_loader = SurvivalAnalysisDataLoader(ds_train, target_column=\"event\", time_to_event_column=\"time\")\n",
    "    surv_gan_model = run_surv_gan(data_loader, device)\n",
    "    surv_vae_model = run_surv_vae(data_loader, device)\n",
    "    \n",
    "    save_to_file(f\"../outputs/model_outputs/sim_model_{dataset_index}_gan.pkl\", surv_gan_model)\n",
    "    save_to_file(f\"../outputs/model_outputs/sim_model_{dataset_index}_vae.pkl\", surv_vae_model)\n",
    "    \n",
    "    generated_data_gan = surv_gan_model.generate(5000)\n",
    "    generated_data_vae = surv_vae_model.generate(5000)\n",
    "    \n",
    "    results, eval_gan = evaluate_model(data_loader, generated_data_gan)\n",
    "    _, eval_vae = evaluate_model(data_loader, generated_data_vae)\n",
    "    print(results)\n",
    "    print(f\"training completed, eval: gan:{eval_gan} vae:{eval_vae}\")\n",
    "    \n",
    "    save_dataset(generated_data_gan, f\"{dataset_index}_gan\",\"../outputs/generated_datasets\")\n",
    "    save_dataset( generated_data_vae, f\"{dataset_index}_vae\",\"../outputs/generated_datasets\")\n",
    "    save_checkpoint(index)\n",
    "    "
   ],
   "id": "256a7e54de2594b0",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
